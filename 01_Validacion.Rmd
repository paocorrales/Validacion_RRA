---
title: "Validación - Obs de superficie"
author: "Pao"
date: "June 4, 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(metR)
library(ggplot2)
library(data.table)
library(lubridate)
library(dplyr)
library(interp)
library(patchwork)
source('read_files.R')
```

Las observaciones asimiladas están en "obs_YYYYMMDD_HH_asimiladas.dat" y contienen las observaciones de la hora anterior. 

Internamente, hay una variable `time.slot` que indica en que subventana se asimiló. Hay 7 ventantas y parecería que el slot 7 de un set de observaciones es igual al slot 1 del set siguiente. *REVISAR*

La variable `obs.id`es númerica y permite clasificar los tipos de observaciones. Los que nos interesan son:

*surface observations codes > 9999*

- id_ps_obs=14593  -> Presión en superficie
- id_us_obs=82819  -> Viento zonal en 10 metros
- id_vs_obs=82820  -> Viento meridional en 10 metros
- id_ts_obs=83073  -> Temperatura en 2 metros
- id_qs_obs=83330  -> Humedad en 2 metros
- id_rhs_obs=83331 -> Humedad relativa

### Pruebas para un tiempo en particular

```{r read_obs}
filepath <- 'data/asimiladas/obs_20181120_00_asimiladas.dat'

obs <- read.obs.asim(filepath)

knitr::kable(head(obs))
```

La función lee un .dat y filtra solo las observaciones de superfice. 

#### Distribución temporal

¿Cuántas osbservaciones hay? ¿Cómo se distribuyen en los slots?

```{r obs.count}
obs[, .N, keyby = .(time.slot, obs.id)] %>% 
  dcast(time.slot ~ obs.id, value.var = 'N') %>% 
  knitr::kable()

ggplot(obs, aes(factor(time.slot))) +
  geom_bar(aes(fill = factor(obs.id))) +
  scale_fill_viridis_d(name = 'obs.id') +
  scale_x_discrete(name = 'time.slot')
```

En el primer y último slot hay un poco más de observaciones porque son las horas en punto *(queda ver que slot1(20181120_00) = 20181119_2300 = slot7(20181119_23))*. En el medio más o menos se mantiene. 

Analicemos la diferencia entre cada observación y el análisis *(¿Cómo hace la comparación? Con el análisis de las 00?)*.

Uso un RMSE para que las diferencias positivas y negativas no se cancelen entre si. Es decir:

$$\sqrt{\sum (ana.obs)^2/N}$$

Para cada tipo de observación y slot.

```{r rmse}
obs[, sqrt(sum(ana.obs^2)/.N), by = .(obs.id, time.slot)] %>% 
  ggplot(aes(time.slot, V1)) + 
  geom_col() + 
  facet_wrap(~ obs.id, scales = 'free')
  
```

En el caso de la presión, el RMSE es tan chico en los primeros slots que no se ve (del orden de 10-3). Lo extraño es que para todas las observaciones, el RMSE se dispara en el último slot. *¿Tendrá que ver con como se genera la diferencia entre la observación y el análisis? Es decir, estas son las observaciones entre las 23:00 y las 00:00 (con nombre 00), se comparan con el analisis de las 23 o el de las 00?*


#### Distribución espacial

Veamos como se distribuyen especialmente las observaciones. Me quedo solo con temperatura a 2 metros.

```{r obs.mapa}

topo <- GetTopography(360-67.5, 360-55, -24, -39, 0.25)
# topo[, lon := ConvertLongitude(lon)]
  
obs[obs.id == 83073] %>% 
  ggplot(aes(lon, lat)) +
  geom_contour(data = topo, aes(z = h), color = "darkgray") +
  geom_point(aes(color = obs), alpha = 0.5) +
  scale_color_viridis_c() +
  facet_wrap(~time.slot)

```

```{r ana.obs.mapa}
obs[obs.id == 83073] %>% 
  ggplot(aes(lon, lat)) +
  geom_contour(data = topo, aes(z = h), color = "darkgray") +
  geom_point(aes(color = ana.obs), alpha = 0.5) +
  scale_color_divergent() +
  facet_wrap(~time.slot)

```

Acá se ve también que en el slot 7 la diferecia analisis - observación es mucho más grande que para el resto. El analisis sobreestima la observación es la mayoría de los casos.

```{r}
obs2 <- read.obs.asim('data/asimiladas/obs_20181120_01_asimiladas.dat')

obs2[, .N, keyby = .(time.slot, obs.id)] %>% 
  dcast(time.slot ~ obs.id, value.var = 'N') %>% 
  knitr::kable()
```

Leo las observaciones del tiempo siguiente (20181120_01) para ver si las del primer slot coinciden con las del último slot del tiempo anterior (20181120_00) y al menos en cantidad no se parecen. Sigo sin entender como se dividen los slots en cada ventana temporal. 

Eso también me genera problemas a la hora de comparar las observaciones con el pronóstico. Si comparo el pronóstico que verifica a las 00 del 20181120, algunas observaciones van a ser casi una hora viejas. No parece una buena comparación. Por eso estoy pensando que capaz es mejor organizar las observaciones en ventanas centradas en la hora de verificación de cada pronóstico. 

Revisando este nuevo tiempo veo que ana.obs es cero en muchísisimas observaciones, básicamente todas las que no están en el slot 7.


### ¿Me quedo con el slot 1 o el 7?

Voy a comparar la cantidad de observaciones que hay en el último slot de un tiempo y el primer slot del siguiente. En principio el slot 1 debería tener más observaciones porque como se asimila después hay más tiempo para que lleguen nuevas observaciones. 

```{r}
#Slots 1 y 7 de 20181120  a las 18 y las 19 horas
obs <- read.obs.asim("data/asimiladas/obs_20181120_1[8-9]_asimiladas.dat", keep.time.slot = c(1, 7)) 

#Quiero el slot 7 del archivo de las 18UTC y el slot 1 del archivo de las 19 UTC. Ambos corresponden a las 18:00
obs <- obs[time.obs == as_datetime("2018-11-20 18:00:00")]

obs[, .N, keyby = .(time.slot, obs.id)] %>% 
  dcast(time.slot ~ obs.id) %>% 
  knitr::kable()
```

Está dando al revez que lo que pensaba.


### Forecast: lectura, interpolación, etc

Para interpolar el pronóstico a cada observación uso el paqute `interp` que parece funcionar de maravillas.

Mientras resuelvo todo lo anterior, voy a comparar derecho con lo que hay.
Por ahora leo solo temperatura a 2 metros de 1 miembro del ensable. Luego veremos como nos las arreglamos para leer todo junto.

```{r}
file.nc <- '../obs_RRA/20181120_00F/NPP_2018-11-20_00_FC00.nc'

# Leo
t2 <- ReadNetCDF(file.nc, vars = c("XLONG", "XLAT", "T2"), subset = list(ens = 1))
t2[, XLONG := ConvertLongitude(XLONG)]

# Solo t2m
t2.asim <- obs[obs.id == 83073]
t2.asim$fcst <- with(t2, interp(XLONG, XLAT, T2, output = 'points', 
                                xo = t2.asim$lon, yo = t2.asim$lat))[['z']]

```

```{r}
p1 <- ggplot(t2.asim, aes(lon, lat)) +
  geom_contour(data = topo, aes(z = h), color = "darkgray") +
  geom_point(aes(color = obs-fcst)) +
  scale_color_divergent() +
  facet_wrap(~time.slot, ncol = 7)

p2 <- ggplot(t2.asim, aes(lon, lat)) +
  geom_contour(data = topo, aes(z = h), color = "darkgray") +
  geom_point(aes(color = obs)) +
  scale_color_viridis_c() +
  facet_wrap(~time.slot, ncol = 7)

p1/p2  
```


Veamos si todo funcionó como queríamos. 

```{r}
obs <- fread("../obs_83073.csv")
obs[, time := as_datetime(time)]
obs[, time.obs := as_datetime(time.obs)]


fcst <- fread("../fcst_83073_20181122_00.csv")
fcst[, time := as_datetime(time)]
fcst[, time.obs := as_datetime(time.obs)]

```

A la izquierda se muestra la diferencia entre las observaciones y el pronóstico para un tiempo y mimebro de ensable determinado. A la derecha se calculó para le mismo tiempo la media del pronóstico antes de hacer la diferencia con las observaciones. No se ven grandes diferencias al menos para este tiempo.

```{r}
fcst[ens == 1 & time.obs == as_datetime("2018-11-22T00:00:00Z")] %>% 
  ggplot(aes(lon, lat)) +
  geom_point(aes(color =  obs - fcst)) + 
  scale_color_divergent(limits = c(-7, 7)) +
  coord_fixed() +
  theme(legend.position="bottom") +

fcst[time.obs == as_datetime("2018-11-22T00:00:00Z")] %>% 
  .[, .(mean = (mean(obs) - mean(fcst))), by = .(lon, lat, ens)] %>% 
  ggplot(aes(lon, lat)) +
  geom_point(aes(color =  mean)) + 
  scale_color_divergent(name = "Diferencia con \nla media del ensamble", limits = c(-7, 7)) +
  coord_fixed() +
  theme(legend.position="bottom")


```

Si calculamos el rmse para todo el periodo vemos que hay algunas estaciones donde el rmse es mayor a 10.

```{r}
fcst[, .(rmse = sqrt(mean((obs - fcst)^2))), by = .(lon, lat)] %>% 
  ggplot(aes(lon, lat)) +
  # geom_point(aes(color = rmse)) 
  geom_point(aes(color = rmse < 10))
  
```

Y mirando la relación entre las observaciones y el pronóstico se ve que si bien hay una relación directa y la mayoría de los puntos se ubican cerca de la recta hay una región donde se ve que el pronóstico sobre estima a las observaciones y algunos puntos anómalos que podrían corresponde a estaciones con problemas sistemáticos.

```{r}
ggplot(fcst, aes(obs, fcst)) + 
  geom_point(alpha = 0.01, size = 0.1)
```

La estación con observaciones de temperatura menor a 275, tiene un valor constante de 173.15 lo que la hace más que sospechosa. Está ubicada en 302.4326 -37.9957 (algo así como Mar del plata). La región de puntos donde el pronóstico sobre esitma mucho a las observaciones corresponde principalmente a observaciones entre las 12 y las 01 UTC. Hay que tener en cuenta que justo estamos mirando un caso de MCS en la región. No parece haber diferencias entre los distintos miembros del emsable. 

```{r}
fcst[obs < 298 & fcst > 302] %>% 
  ggplot(aes(lon, lat)) +
  geom_point(aes(color = obs-fcst)) +
  facet_wrap(~factor(time.obs))

```


### Fcst

```{r}
fcst <- ReadNetCDF("../obs_RRA/20181122_00F/NPP_2018-11-22_00_FC18.nc", vars = c("XLONG", "XLAT", "MDBZ"))

fcst[ens %in% c(1:10)] %>% 
ggplot(aes(lon, lat)) +
  geom_point(aes(color = MDBZ)) +
  scale_color_viridis_c(limits = c(0, 50)) +
  facet_wrap(~ens, ncol = 5)
```




